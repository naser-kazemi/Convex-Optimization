{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c02d883",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252273de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f31819",
   "metadata": {},
   "source": [
    "# Data Processing for Network Cascades and Adjacency Matrices\n",
    "\n",
    "This code consists of three functions designed to process and interpret data related to network cascades and adjacency matrices. These functions are crucial for understanding network dynamics and structures in various applications such as social network analysis, information dissemination, and epidemiological studies.\n",
    "\n",
    "## Function: `create_cascades`\n",
    "\n",
    "### Purpose\n",
    "- Generates a matrix representing cascades in a network based on input data.\n",
    "\n",
    "## Function: `create_adj_matrix`\n",
    "\n",
    "### Purpose\n",
    "- Creates an adjacency matrix for a network based on input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_variable_columns(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            columns = line.strip().split(',')\n",
    "            data.append(columns)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_cascades(filename, num_nodes):\n",
    "\n",
    "    # check if the file exists\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(\"File not found\")\n",
    "\n",
    "    # read the file\n",
    "    v = read_variable_columns(filename)\n",
    "\n",
    "    # initialize C (The cascades) with -1\n",
    "    C = - np.ones((len(v), num_nodes), dtype=float)\n",
    "\n",
    "    # loop through each row in v\n",
    "    for i in range(len(v)):\n",
    "        if int(v[i][0]) < num_nodes:\n",
    "            C[i, int(v[i][0])] = v[i][1]\n",
    "\n",
    "        j = 2\n",
    "        while j < len(v[i]) and int(v[i][j]) > -1:\n",
    "            if int(v[i][j]) < num_nodes:\n",
    "                C[i, int(v[i][j])] = v[i][j+1]\n",
    "            j += 2\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "def create_adj_matrix(filename, num_nodes):\n",
    "    # initialize the adjacency matrix with zero\n",
    "    A = np.zeros((num_nodes, num_nodes), dtype=float)\n",
    "\n",
    "    # check if file exists\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(\"File not found\")\n",
    "\n",
    "    # read the file\n",
    "    v = read_variable_columns(filename)\n",
    "    v = v[:num_nodes]\n",
    "\n",
    "    # loop through each row in v to populate the adjacency matrix\n",
    "    for i in range(len(v)):\n",
    "        if int(v[i][0]) < num_nodes and int(v[i][1]) < num_nodes:\n",
    "            A[int(v[i][0]), int(v[i][1])] = v[i][2]\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af09021",
   "metadata": {},
   "source": [
    "# Network Estimation Based on Diffusion Models\n",
    "\n",
    "This code comprises three functions that collectively estimate a network's structure by considering different diffusion models. \n",
    "\n",
    "## Function: `add_log_survival`\n",
    "\n",
    "### Purpose\n",
    "- Updates the log-survival function based on the diffusion model.\n",
    "\n",
    "## Function: `add_constraints`\n",
    "\n",
    "### Purpose\n",
    "- Adds constraints to a convex optimization problem based on the type of diffusion.\n",
    "\n",
    "## Function: `estimate_network`\n",
    "\n",
    "### Purpose\n",
    "- Estimates the network structure using a convex optimization approach.\n",
    "\n",
    "### Process\n",
    "1. **Initialization:**\n",
    "   - Sets up various matrices (`A_potential`, `A_bad`, `A_hat`) and initializes a counter for cascades per node.\n",
    "2. **Cascade Processing:**\n",
    "   - Iterates through each cascade, updating `A_potential` and `A_bad` using `add_log_survival`.\n",
    "3. **Convex Optimization:**\n",
    "   - For each node, sets up and solves a convex optimization problem to estimate network connections.\n",
    "   - Uses `cp.Variable` to create optimization variables.\n",
    "   - Adds constraints and objectives specific to the diffusion model and solves the problem.\n",
    "4. **Result Compilation:**\n",
    "   - Aggregates results into `A_hat`, representing the estimated network structure.\n",
    "   - Returns the estimated network `A_hat` and the total objective function value `total_obj`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3933fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_log_survival(A, i, j, diff, type_diffusion):\n",
    "    if type_diffusion == 'exp':\n",
    "        A[i, j] += diff\n",
    "    elif type_diffusion == 'pl':\n",
    "        A[i, j] += np.log(diff)\n",
    "    elif type_diffusion == 'rayleigh':\n",
    "        A[i, j] += 0.5 * (diff) ** 2\n",
    "\n",
    "\n",
    "def add_constraints(constraints, a_hat, t_hat, c_act, val, idx_ord, cidx, type_diffusion):\n",
    "    if type_diffusion == 'exp':\n",
    "        constraints.append(t_hat[c_act] == cp.sum(a_hat[idx_ord[:cidx[0]]]))\n",
    "    elif type_diffusion == 'pl':\n",
    "        tdifs = 1.0 / (val[cidx[0]] - val[:cidx[0]])\n",
    "        indv = np.where(tdifs < 1)[0]\n",
    "        tdifs = tdifs[indv]\n",
    "        constraints.append(t_hat[c_act] <= cp.sum(\n",
    "            tdifs * a_hat[idx_ord[indv]]))\n",
    "    elif type_diffusion == 'rayleigh':\n",
    "        tdifs = (val[cidx[0]] - val[:cidx[0]])\n",
    "        constraints.append(t_hat[c_act] <= cp.sum(\n",
    "            tdifs * a_hat[idx_ord[:cidx[0]]]))\n",
    "\n",
    "\n",
    "def estimate_network(A, C, num_nodes, horizon, type_diffusion):\n",
    "    num_cascades = np.zeros(num_nodes)\n",
    "    A_potential = lil_matrix(np.zeros(A.shape))\n",
    "    A_bad = lil_matrix(np.zeros(A.shape))\n",
    "    A_hat = lil_matrix(np.zeros(A.shape))\n",
    "    total_obj = 0\n",
    "\n",
    "    for c in range(C.shape[0]):\n",
    "        idx = np.where(C[c, :] != -1)[0]  # used nodes\n",
    "        val = np.sort(C[c, idx])\n",
    "        order = np.argsort(val)\n",
    "\n",
    "        for i in range(1, len(val)):\n",
    "            num_cascades[idx[order[i]]] += 1\n",
    "            for j in range(i):\n",
    "                diff = val[i] - val[j]\n",
    "                add_log_survival(\n",
    "                    A_potential, idx[order[j]], idx[order[i]], diff, type_diffusion)\n",
    "\n",
    "        for j in range(num_nodes):\n",
    "            if j not in idx:\n",
    "                for i in range(len(val)):\n",
    "                    diff = horizon - val[i]\n",
    "                    add_log_survival(\n",
    "                        A_bad, idx[order[i]], j, diff, type_diffusion)\n",
    "\n",
    "    # convex program per column\n",
    "    for i in range(num_nodes):\n",
    "        if num_cascades[i] == 0:\n",
    "            continue\n",
    "        print(f'Processing node {i}...')\n",
    "        a_hat = cp.Variable(num_nodes)\n",
    "        t_hat = cp.Variable(int(num_cascades[i]))\n",
    "        obj = 0\n",
    "\n",
    "        potential_indices = A_potential[:, i].nonzero()[0]\n",
    "        bad_indices = A_bad[:, i].nonzero()[0]\n",
    "\n",
    "        constraints = [a_hat[potential_indices] >= 0]\n",
    "\n",
    "        for j in potential_indices:\n",
    "            obj += -a_hat[j] * (A_potential[j, i] + A_bad[j, i])\n",
    "\n",
    "        c_act = 0\n",
    "        for c in range(C.shape[0]):\n",
    "            idx = np.where(C[c, :] != -1)[0]  # used nodes\n",
    "            val = np.sort(C[c, idx])\n",
    "            order = np.argsort(val)\n",
    "            idx_ord = idx[order]\n",
    "            cidx = np.where(idx_ord == i)[0]\n",
    "\n",
    "            if cidx.size > 0 and cidx[0] > 0:\n",
    "                add_constraints(constraints, a_hat, t_hat, c_act,\n",
    "                                val, idx_ord, cidx, type_diffusion)\n",
    "                obj += cp.log(t_hat[c_act])\n",
    "                c_act += 1\n",
    "\n",
    "        constraints += [a_hat >= 0]\n",
    "\n",
    "        problem = cp.Problem(cp.Maximize(obj), constraints)\n",
    "        problem.solve(solver=cp.CLARABEL, verbose=False)\n",
    "\n",
    "        total_obj += problem.value\n",
    "        A_hat[:, i] = a_hat.value\n",
    "\n",
    "    return A_hat, total_obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadd343",
   "metadata": {},
   "source": [
    "# Function: `netrate`\n",
    "\n",
    "## Overview\n",
    "The `netrate` function is the core of the network estimation process, integrating various components to estimate a network's structure based on diffusion models. It involves reading and processing network and cascades data, estimating the network structure, and evaluating its accuracy.\n",
    "\n",
    "## Parameters\n",
    "- `network`: Path to the network file.\n",
    "- `cascades`: Path to the cascades data file.\n",
    "- `horizon`: Time horizon for the cascades.\n",
    "- `type_diffusion`: Type of diffusion model used (e.g., 'exp', 'pl', 'rayleigh').\n",
    "- `num_nodes`: Number of nodes in the network.\n",
    "\n",
    "## Process\n",
    "\n",
    "### 1. Initialization\n",
    "- Sets a minimum tolerance level `min_tol` for the network estimation.\n",
    "- Initializes an array `pr` for precision and recall values.\n",
    "\n",
    "### 2. Reading Ground-Truth Network\n",
    "- Reads the ground-truth network from `network` using the `create_adj_matrix` function.\n",
    "\n",
    "### 3. Reading Cascades Data\n",
    "- Reads and processes the cascades data from `cascades` using the `create_cascades` function.\n",
    "\n",
    "### 4. Estimating the Network\n",
    "- Calls `estimate_network` with the ground-truth network `A`, cascades `C`, and other parameters to estimate the network structure.\n",
    "- Receives the estimated network `A_hat` and the total objective function value `total_obj`.\n",
    "\n",
    "### 5. Accuracy Evaluation\n",
    "- If a ground-truth network is available, calculates Mean Absolute Error (MAE), precision, and recall to evaluate the accuracy of `A_hat`.\n",
    "- Compares `A_hat` with the ground-truth `A` to compute these metrics.\n",
    "- Constructs binary versions of `A` and `A_hat` to calculate precision and recall.\n",
    "\n",
    "### 6. Result Saving\n",
    "- Extracts the network name from the `network` path.\n",
    "- Saves the results (estimated network, MAE, precision, recall, total objective) to a file in the `Result` directory.\n",
    "\n",
    "## Returns\n",
    "- `A_hat`: The estimated network matrix.\n",
    "- `total_obj`: The total objective function value from the network estimation.\n",
    "- `pr`: Precision and recall values, if applicable.\n",
    "- `mae`: Mean Absolute Error, if applicable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def netrate(network, cascades, horizon, type_diffusion, num_nodes):\n",
    "    min_tol = 1e-4\n",
    "\n",
    "    pr = np.zeros(2)\n",
    "\n",
    "    print('Reading ground-truth...')\n",
    "    A = create_adj_matrix(network, num_nodes)\n",
    "\n",
    "    print('Reading cascades...')\n",
    "    C = create_cascades(cascades, num_nodes)\n",
    "\n",
    "    print('Building data structures...')\n",
    "    A_hat, total_obj = estimate_network(\n",
    "        A, C, num_nodes, horizon, type_diffusion)\n",
    "\n",
    "    if os.path.exists(network):\n",
    "        non_zero_mask = (A != 0)\n",
    "        A_non_zero = A[non_zero_mask]\n",
    "        A_hat_non_zero = A_hat[non_zero_mask]\n",
    "        mae = np.mean(np.abs(A_hat_non_zero - A_non_zero) / A_non_zero)\n",
    "\n",
    "        # Compute precision and recall\n",
    "        A_hat_binary = A_hat > min_tol\n",
    "        A_binary = A > min_tol\n",
    "\n",
    "        # Element-wise logical AND using the multiply method\n",
    "        intersection = A_hat_binary.multiply(A_binary)\n",
    "        recall = intersection.sum() / A_binary.sum()\n",
    "        precision = intersection.sum() / A_hat_binary.sum()\n",
    "        pr = np.array([precision, recall])\n",
    "    else:\n",
    "        mae = None\n",
    "        pr = None\n",
    "\n",
    "    network = network.split('/')[-1].split('.')[0]\n",
    "\n",
    "    # Saving the results\n",
    "    with open(f'Result/solution-{network}.pkl', 'wb') as f:\n",
    "        pickle.dump({'A_hat': A_hat, 'mae': mae,\n",
    "                    'pr': pr, 'total_obj': total_obj}, f)\n",
    "\n",
    "    return A_hat, total_obj, pr, mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "network_file = '../Data/kronecker-core-periphery-n1024-h10-r0_01-0_25-network.txt'\n",
    "cascades_file = '../Data/kronecker-core-periphery-n1024-h10-r0_01-0_25-1000-cascades.txt'\n",
    "\n",
    "# network_file = '../Data/netinf-512-network.txt'\n",
    "# cascades_file = '../Data/netinf-512-cascades.txt'\n",
    "\n",
    "\n",
    "horizon = 20\n",
    "type_diffusion = 'exp'\n",
    "num_nodes = 200  # number of nodes in Kronecker graph\n",
    "# num_nodes = 512 # number of nodes in NetInf graph\n",
    "\n",
    "\n",
    "A_hat, total_obj, pr, mae = netrate(\n",
    "    network_file, cascades_file, horizon, type_diffusion, num_nodes)\n",
    "\n",
    "# convert A_hat to matrix\n",
    "A_hat = A_hat.toarray()\n",
    "\n",
    "A = create_adj_matrix(network_file, num_nodes)\n",
    "\n",
    "# print the results\n",
    "print(f'Precision: {pr[0]}')\n",
    "print(f'Recall: {pr[1]}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Total Objective: {total_obj}')\n",
    "\n",
    "# Save the results\n",
    "network = network_file.split('/')[-1].split('.')[0]\n",
    "\n",
    "# make the Result/{network} directory if it does not exist\n",
    "if not os.path.exists(f'Result/{network}'):\n",
    "    os.mkdir(f'Result/{network}')\n",
    "\n",
    "\n",
    "with open(f'solution.pkl', 'wb') as f:\n",
    "    pickle.dump({'A_hat': A_hat, 'mae': mae,\n",
    "                'pr': pr, 'total_obj': total_obj}, f)\n",
    "\n",
    "\n",
    "# save the plots, beautify the plots with seaborn for the graphs. note that the graphs are relatively large\n",
    "G = nx.from_numpy_array(A_hat)\n",
    "nx.draw(G, with_labels=True, font_weight='bold', node_size=100, node_color='skyblue', font_size=8, edge_color='gray',\n",
    "        linewidths=0.5, width=0.5, alpha=0.7, pos=nx.spring_layout(G), arrowsize=10, arrowstyle='->', connectionstyle='arc3, rad = 0.1', edge_cmap=plt.cm.Blues)\n",
    "plt.savefig(f'Result/{network}/A_hat_{num_nodes}.png', dpi=300)\n",
    "\n",
    "G = nx.from_numpy_array(A)\n",
    "nx.draw(G, with_labels=True, font_weight='bold', node_size=100, node_color='skyblue', font_size=8, edge_color='gray',\n",
    "        linewidths=0.5, width=0.5, alpha=0.7, pos=nx.spring_layout(G), arrowsize=10, arrowstyle='->', connectionstyle='arc3, rad = 0.1', edge_cmap=plt.cm.Blues)\n",
    "plt.savefig(f'Result/{network}/A_{num_nodes}.png', dpi=300)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
